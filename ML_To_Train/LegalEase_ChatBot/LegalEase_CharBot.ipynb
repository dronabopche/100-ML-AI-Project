{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bffcd0a7",
   "metadata": {},
   "source": [
    "# LegalEase_ChatBot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44583dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/classEnv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/classEnv/lib/python3.13/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/classEnv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/classEnv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/classEnv/lib/python3.13/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/classEnv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install -q transformers datasets accelerate evaluate sentencepiece  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf8a05d",
   "metadata": {},
   "source": [
    "# 1. importing libabries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb5897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/classEnv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51cefb",
   "metadata": {},
   "source": [
    "# 2. importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd12557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the difference between a petition and ...</td>\n",
       "      <td>A petition is a formal request submitted to a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When should a writ petition be filed in India?</td>\n",
       "      <td>A writ petition in India should be filed when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the procedure for filing a plaint in a...</td>\n",
       "      <td>To file a plaint in a civil case in Indiayou m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the common reliefs sought through a p...</td>\n",
       "      <td>Public interest litigation (PIL) petitions in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can a plaint be amended after it has been file...</td>\n",
       "      <td>Yesa plaint can be amended in a civil case in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28684</th>\n",
       "      <td>Which schedule includes small scale industries...</td>\n",
       "      <td>The Eleventh Schedule includes these industries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28685</th>\n",
       "      <td>What welfare programs are included in the Elev...</td>\n",
       "      <td>Family welfare, Women and child development, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28686</th>\n",
       "      <td>Which Schedule includes programs such as famil...</td>\n",
       "      <td>These programs are included in the Eleventh Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28687</th>\n",
       "      <td>What does the twelfth schedule of Article 243W...</td>\n",
       "      <td>Urban planning including town planning, regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28688</th>\n",
       "      <td>Which article and schedule includes the regula...</td>\n",
       "      <td>The twelfth schedule of Article 243W includes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28689 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      What is the difference between a petition and ...   \n",
       "1         When should a writ petition be filed in India?   \n",
       "2      What is the procedure for filing a plaint in a...   \n",
       "3      What are the common reliefs sought through a p...   \n",
       "4      Can a plaint be amended after it has been file...   \n",
       "...                                                  ...   \n",
       "28684  Which schedule includes small scale industries...   \n",
       "28685  What welfare programs are included in the Elev...   \n",
       "28686  Which Schedule includes programs such as famil...   \n",
       "28687  What does the twelfth schedule of Article 243W...   \n",
       "28688  Which article and schedule includes the regula...   \n",
       "\n",
       "                                                  answer  \n",
       "0      A petition is a formal request submitted to a ...  \n",
       "1      A writ petition in India should be filed when ...  \n",
       "2      To file a plaint in a civil case in Indiayou m...  \n",
       "3      Public interest litigation (PIL) petitions in ...  \n",
       "4      Yesa plaint can be amended in a civil case in ...  \n",
       "...                                                  ...  \n",
       "28684   The Eleventh Schedule includes these industries.  \n",
       "28685  Family welfare, Women and child development, S...  \n",
       "28686  These programs are included in the Eleventh Sc...  \n",
       "28687  Urban planning including town planning, regula...  \n",
       "28688  The twelfth schedule of Article 243W includes ...  \n",
       "\n",
       "[28689 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('dataset/legal_qa.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c440f694",
   "metadata": {},
   "source": [
    "# 3) Basic cleaning + formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba9b629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question:\n",
      "What is the difference between a petition and a plaint in Indian law?\n",
      "\n",
      "### Answer:\n",
      "A petition is a formal request submitted to a courttribunalor authority to seek a specific remedy or relief. It is commonly used for various purposessuch as filing a writ petition in the High Court or submitting a petition for divorce. On the other handa plaint is a formal written statement of a plaintiff's claim in a civil lawsuit. The key difference is that a petition is more versatile and can be used for various legal matterswhile a plaint is specific to civil cases.\n",
      "\n",
      "Rows: 28689\n"
     ]
    }
   ],
   "source": [
    "data = data.copy()\n",
    "\n",
    "data[\"question\"] = data[\"question\"].astype(str).str.strip()\n",
    "data[\"answer\"] = data[\"answer\"].astype(str).str.strip()\n",
    "\n",
    "# remove empty rows\n",
    "data = data[(data[\"question\"].str.len() > 0) & (data[\"answer\"].str.len() > 0)].reset_index(drop=True)\n",
    "\n",
    "def format_qa(q, a):\n",
    "    return f\"### Question:\\n{q}\\n\\n### Answer:\\n{a}\\n\"\n",
    "\n",
    "data[\"text\"] = data.apply(lambda row: format_qa(row[\"question\"], row[\"answer\"]), axis=1)\n",
    "\n",
    "print(data[\"text\"].iloc[0])\n",
    "print(\"Rows:\", len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e37ff8",
   "metadata": {},
   "source": [
    "\n",
    "# 4) Convert to HuggingFace Dataset + split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7f743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2869\n",
      "}) Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 25820\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "hf_ds = Dataset.from_pandas(data[[\"text\"]])\n",
    "\n",
    "split = hf_ds.train_test_split(test_size=0.1, seed=42)\n",
    "val_ds = split[\"train\"]\n",
    "train_ds = split[\"test\"]\n",
    "\n",
    "print(train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bdd6f1",
   "metadata": {},
   "source": [
    "\n",
    "# 5) Load GPT-2 tokenizer + model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a8f0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 148/148 [00:00<00:00, 1194.38it/s, Materializing param=transformer.wte.weight]             \n",
      "\u001b[1mGPT2LMHeadModel LOAD REPORT\u001b[0m from: gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"gpt2\"   # small GPT-2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# GPT-2 has no pad token by default → set pad token = eos token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55baf7",
   "metadata": {},
   "source": [
    "\n",
    "# 6) Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49147133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2869/2869 [00:00<00:00, 5536.19 examples/s]\n",
      "Map: 100%|██████████| 25820/25820 [00:04<00:00, 5441.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 384  # for MacBook keep smaller; later on GPU you can use 512/1024\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    out = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    out[\"labels\"] = out[\"input_ids\"].copy()\n",
    "    return out\n",
    "\n",
    "train_tok = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "val_tok = val_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400141c",
   "metadata": {},
   "source": [
    "# 7) Data collator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40091a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e05ac",
   "metadata": {},
   "source": [
    "\n",
    "# 8) Training arguments (Mac-friendly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8e186b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "\n",
    "    # NEW in v5\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=300,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fd530",
   "metadata": {},
   "source": [
    "# 9) Trainer + Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983de3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/classEnv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='359' max='359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [359/359 1:53:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>7.297839</td>\n",
       "      <td>6.512819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=359, training_loss=6.189120810676086, metrics={'train_runtime': 6839.8412, 'train_samples_per_second': 0.419, 'train_steps_per_second': 0.052, 'total_flos': 562235129856000.0, 'train_loss': 6.189120810676086, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773a3e2",
   "metadata": {},
   "source": [
    "# 10) Evaluation metrics (Loss + Perplexity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308dd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n",
    "\n",
    "# perplexity = exp(loss)\n",
    "loss = eval_results[\"eval_loss\"]\n",
    "perplexity = math.exp(loss)\n",
    "\n",
    "print(f\"\\nEval Loss: {loss:.4f}\")\n",
    "print(f\"Perplexity: {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e4625",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 11) Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc317e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/tokenizer_config.json', 'models/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"models\")\n",
    "tokenizer.save_pretrained(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4ae8a",
   "metadata": {},
   "source": [
    "\n",
    "# 12) Inference function (Ask the chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f05d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_bot(question, max_new_tokens=180, temperature=0.7, top_p=0.9):\n",
    "    prompt = f\"### Question:\\n{question}\\n\\n### Answer:\\n\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Return only the answer part\n",
    "    if \"### Answer:\" in decoded:\n",
    "        return decoded.split(\"### Answer:\")[-1].strip()\n",
    "    return decoded.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de0394ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "​ in the power in the jurisdiction in a law as a the\n",
      "b: theט the right of the any other that the legislative so of a issue this\n",
      " theb the law\n",
      " the\n",
      " the�b\n",
      " the the 15\n",
      " the specifically how\n",
      "\n",
      " theט (\n",
      ", the a the a a in the the\n",
      "\n",
      " the\n",
      " a the\n",
      " the've\n",
      "\n",
      "​ itsb a\n",
      "\n",
      " a the the services the\n",
      " the\n",
      " the\n",
      "btheless\n",
      " the\n",
      " the the\n",
      " the\n",
      " the\n",
      "\n",
      " the\n",
      "\n",
      " from a in the the\n",
      "\n",
      "� law\n",
      "\n",
      "\n",
      "\n",
      " or this 2 aא the\n",
      " the\n",
      "\n",
      " that a\n",
      "\n",
      " the\n",
      " the has\n",
      "\n",
      "b\n",
      "\n",
      "\" theאו�ט its\n",
      " the the\n",
      "\n",
      " the\n",
      " and on a\n",
      "\n",
      " the, a the 2\n",
      "\n",
      "b\n",
      " a and be\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Test it:\n",
    "print(ask_bot(\"What is the punishment for cheque bounce in India?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7b862",
   "metadata": {},
   "source": [
    "# 13. To save pickel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52bcc043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open(\"models/LegalQA.pkl\", \"wb\") as file:  #\n",
    "    pickle.dump(model, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d38e1d17",
   "metadata": {},
   "source": [
    "# Iris Flower Prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec77f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipykernel\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b809c47",
   "metadata": {},
   "source": [
    "\n",
    "# 1. importing all basic libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.metrics import (r2_score, accuracy_score, precision_score, \n",
    "                           recall_score, f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b035d",
   "metadata": {},
   "source": [
    "# 2. data loading and refining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"iris_dataset.csv\")\n",
    "\n",
    "iris_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1de6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d856537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping the speices\n",
    "iris_df[\"Species\"] = iris_df[\"Species\"].map({\"Iris-setosa\" : 0,\n",
    "                                             \"Iris-versicolor\" :1,\n",
    "                                             \"Iris-virginica\": 2\n",
    "                                             })\n",
    "\n",
    "\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf759c3",
   "metadata": {},
   "source": [
    "# 3. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8cbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_df.drop(columns= [\"Species\" , \"Id\"])\n",
    "Y = iris_df[\"Species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dad888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a9a36",
   "metadata": {},
   "source": [
    "# 3. Training data on logistic reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn .linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=10,\n",
    "    solver='lbfgs'  \n",
    ").fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = log_model.predict(X_test)\n",
    "\n",
    "#calculate metrics\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, Y_predict)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(Y_test, Y_predict,average='micro')*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(Y_test, Y_predict,average='micro')*100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(Y_test, Y_predict,average='micro')*100:.2f}%\")\n",
    "print(f\"R2 Score: {r2_score(Y_test, Y_predict):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3ce53",
   "metadata": {},
   "source": [
    "# 4.Training data on Navie bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb47967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB().fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gnb.predict(X_test)\n",
    "\n",
    "#calculate metrics\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, Y_pred)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(Y_test, Y_pred,average='micro')*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(Y_test, Y_pred,average='micro')*100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(Y_test, Y_pred,average='micro')*100:.2f}%\")\n",
    "print(f\"R2 Score: {r2_score(Y_test, Y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9443426",
   "metadata": {},
   "source": [
    "# 5. Training data on KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbb139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=3).fit(X_train, Y_train)\n",
    "\n",
    "Y_prediction = KNN.predict(X_test)\n",
    "\n",
    "#calculate metrics\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, Y_prediction)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(Y_test, Y_prediction,average='micro')*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(Y_test, Y_prediction,average='micro')*100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(Y_test, Y_prediction,average='micro')*100:.2f}%\")\n",
    "print(f\"R2 Score: {r2_score(Y_test, Y_prediction):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad9117e",
   "metadata": {},
   "source": [
    "# 6. Pickling the Model For deployment\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8163da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open(\"iris_model.pkl\", \"wb\") as file:  #\n",
    "    pickle.dump(KNN, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2564f4b",
   "metadata": {},
   "source": [
    "# 7. Making the requirement File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "# List of the packages you know you're using\n",
    "required_packages = [\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'scikit-learn',\n",
    "    'matplotlib',\n",
    "    'seaborn',\n",
    "    'ipykernel',\n",
    "]\n",
    "\n",
    "requirements = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        requirements.append(f\"{package}=={version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"Package {package} not found in the environment.\")\n",
    "\n",
    "#requirements to a file\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    for line in requirements:\n",
    "        f.write(line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
